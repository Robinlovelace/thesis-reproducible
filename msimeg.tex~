Spatial microsimulation in R: a beginner's guide to iterative
proportional fitting (IPF)

========================================================

\subsection{Introduction}

This section contributes to my thesis on the energy costs of travel to
work.

\subsection{Input data}

Spatial microsimulation requires two input datasets: individual-level
data, where rows represent individuals, and geographically aggregated
data, where rows represent areas. The following code creates example
datasets, based on a survey of 5 individuals and 5 small areas. The
spatial microsimulation model will select individuals based on age, sex
and mode of transport. For consistency with the (larger) model used for
the paper, we will refer to the individual-level data as USd (short for
Understanding Society dataset) and the geographic data as all.msim (all
constraint variables).

\subsubsection{Individual-level data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read in the data in long form (normaly read.table() used)}
\NormalTok{c.names <- }\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"sex"}\NormalTok{)}
\NormalTok{USd <- }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{59}\NormalTok{, }\StringTok{"m"}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{54}\NormalTok{, }\StringTok{"m"}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{35}\NormalTok{, }\StringTok{"m"}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{73}\NormalTok{, }\StringTok{"f"}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{49}\NormalTok{, }\StringTok{"f"}\NormalTok{)}
\NormalTok{USd <- }\KeywordTok{matrix}\NormalTok{(USd, }\DataTypeTok{nrow =} \DecValTok{5}\NormalTok{, }\DataTypeTok{byrow =} \NormalTok{T)  }\CommentTok{# Convert long data into matrix, by row}
\NormalTok{USd <- }\KeywordTok{data.frame}\NormalTok{(USd)  }\CommentTok{# Convert this into a dataframe}
\KeywordTok{names}\NormalTok{(USd) <- c.names  }\CommentTok{# Add correct column names}
\NormalTok{USd$age <- }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{levels}\NormalTok{(USd$age)[USd$age])  }\CommentTok{# Age is a numeric variable}

\NormalTok{USd  }\CommentTok{# Show the data frame in R}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##   id age sex
## 1  1  59   m
## 2  2  54   m
## 3  3  35   m
## 4  4  73   f
## 5  5  49   f
\end{verbatim}
\subsubsection{Geographical data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Read in the data in long form (normaly read.table() used)}
\NormalTok{category.labels <- }\KeywordTok{c}\NormalTok{(}\StringTok{"16-49"}\NormalTok{, }\StringTok{"50+"} \CommentTok{# Age constraint }
             \NormalTok{,}\StringTok{"m"}\NormalTok{, }\StringTok{"f"} \CommentTok{# Sex constraint}
             \CommentTok{#,"bicycle", "bus", "car.d", "car.p", "walk" # Mode constraint}
             \NormalTok{)}
\NormalTok{all.msim <- }\KeywordTok{c}\NormalTok{(  }\DecValTok{8}\NormalTok{, }\DecValTok{4}\NormalTok{,    }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{,   }\CommentTok{#0.001, 1, 8, 1, 0.001, # Car dominated}
                \DecValTok{2}\NormalTok{, }\DecValTok{8}\NormalTok{,    }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{,   }\CommentTok{#0.001, 3, 5, 1, 1, # Elderly}
                \DecValTok{7}\NormalTok{, }\DecValTok{4}\NormalTok{,    }\DecValTok{3}\NormalTok{, }\DecValTok{8}\NormalTok{,   }\CommentTok{#1, 2, 5, 2, 1, # Female dominated}
                \DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{,    }\DecValTok{7}\NormalTok{, }\DecValTok{2}\NormalTok{,   }\CommentTok{#2, 1, 3, 1, 2, # Male dominated}
                \DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{,    }\DecValTok{6}\NormalTok{, }\DecValTok{4}    \CommentTok{#,   7, 0.001, 2, 0.001, 1  # Many cyclists, young}
                \NormalTok{)}
\NormalTok{all.msim <- }\KeywordTok{matrix}\NormalTok{(all.msim, }\DataTypeTok{nrow =} \DecValTok{5}\NormalTok{, }\DataTypeTok{byrow =} \NormalTok{T) }\CommentTok{# Convert long data into matrix, by row}
\NormalTok{all.msim <- }\KeywordTok{data.frame}\NormalTok{(all.msim) }\CommentTok{# Convert this into a dataframe}
\KeywordTok{names}\NormalTok{(all.msim) <- category.labels }\CommentTok{# Add correct column names}
\NormalTok{all.msim }\CommentTok{# Show the data frame in R}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##   16-49 50+ m f
## 1     8   4 6 6
## 2     2   8 4 6
## 3     7   4 3 8
## 4     5   4 7 2
## 5     7   3 6 4
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{# Check totals for each constraint match}
\KeywordTok{rowSums}\NormalTok{(all.msim[,}\DecValTok{1}\NormalTok{:}\DecValTok{2}\NormalTok{]) }\CommentTok{# Age constraint}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
## [1] 12 10 11  9 10
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rowSums}\NormalTok{(all.msim[,}\DecValTok{3}\NormalTok{:}\DecValTok{4}\NormalTok{]) }\CommentTok{# Sex constraint}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
## [1] 12 10 11  9 10
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]

\KeywordTok{rowSums}\NormalTok{(all.msim[,}\DecValTok{1}\NormalTok{:}\DecValTok{2}\NormalTok{]) == }\KeywordTok{rowSums}\NormalTok{(all.msim[,}\DecValTok{3}\NormalTok{:}\DecValTok{4}\NormalTok{]) }
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
## [1] TRUE TRUE TRUE TRUE TRUE
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#rowSums(all.msim[,6:10])# Mode constraint}
\end{Highlighting}
\end{Shaded}
\subsection{Reweighting the survey dataset}

Iterative proportional fitting will determine the weight allocated to
each individual for each zone to best match the geographically
aggregated data. A weight matrix is therefore created, with rows
corresponding to individuals and columns to zones.

\subsubsection{Create weights: one set of weights for each constraint
and one for starting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{weights0 <- }\KeywordTok{array}\NormalTok{(}\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(USd), }\KeywordTok{nrow}\NormalTok{(all.msim)))}
\NormalTok{weights1 <- }\KeywordTok{array}\NormalTok{(}\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(USd), }\KeywordTok{nrow}\NormalTok{(all.msim)))}
\NormalTok{weights2 <- }\KeywordTok{array}\NormalTok{(}\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(USd), }\KeywordTok{nrow}\NormalTok{(all.msim)))}
\CommentTok{# weights3 <- array(dim=c(nrow(USd),nrow(all.msim)))}

\NormalTok{weights0[, ] <- }\DecValTok{1}  \CommentTok{# sets initial weights to 1}
\end{Highlighting}
\end{Shaded}
\subsubsection{Create survey aggregate arrays (for direct comparison
with the geographical aggregate data)}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{USd.agg <- }\KeywordTok{array}\NormalTok{(}\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(all.msim), }\KeywordTok{ncol}\NormalTok{(all.msim)))}
\NormalTok{USd.agg1 <- }\KeywordTok{array}\NormalTok{(}\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(all.msim), }\KeywordTok{ncol}\NormalTok{(all.msim)))}
\NormalTok{USd.agg2 <- }\KeywordTok{array}\NormalTok{(}\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(all.msim), }\KeywordTok{ncol}\NormalTok{(all.msim)))}
\KeywordTok{colnames}\NormalTok{(USd.agg1) <- category.labels}
\end{Highlighting}
\end{Shaded}
\subsubsection{Convert survey data into wide form}

This step allows the individual-level data to be compared with the
aggregated data directly

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{USd.cat <- }\KeywordTok{array}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{), }\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(USd), }\KeywordTok{length}\NormalTok{(category.labels != }\DecValTok{0}\NormalTok{)))}

\NormalTok{USd.cat[}\KeywordTok{which}\NormalTok{(USd$age < }\DecValTok{50}\NormalTok{), }\DecValTok{1}\NormalTok{] <- }\DecValTok{1}
\NormalTok{USd.cat[}\KeywordTok{which}\NormalTok{(USd$age >= }\DecValTok{50}\NormalTok{), }\DecValTok{2}\NormalTok{] <- }\DecValTok{1}
\NormalTok{USd.cat[}\KeywordTok{which}\NormalTok{(USd$sex == }\StringTok{"m"}\NormalTok{), }\DecValTok{3}\NormalTok{] <- }\DecValTok{1}
\NormalTok{USd.cat[}\KeywordTok{which}\NormalTok{(USd$sex == }\StringTok{"f"}\NormalTok{), }\DecValTok{4}\NormalTok{] <- }\DecValTok{1}
\KeywordTok{sum}\NormalTok{(USd.cat)  }\CommentTok{# Should be 10}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
## [1] 10
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{for (i in }\DecValTok{1}\NormalTok{:}\KeywordTok{nrow}\NormalTok{(all.msim)) \{}
    \CommentTok{# Loop creating aggregate values (to be repeated later)}
    \NormalTok{USd.agg[i, ] <- }\KeywordTok{colSums}\NormalTok{(USd.cat * weights0[, i])}
\NormalTok{\}}

\CommentTok{# Test results}
\NormalTok{USd.agg}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    2    3    3    2
## [2,]    2    3    3    2
## [3,]    2    3    3    2
## [4,]    2    3    3    2
## [5,]    2    3    3    2
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.msim}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##   16-49 50+ m f
## 1     8   4 6 6
## 2     2   8 4 6
## 3     7   4 3 8
## 4     5   4 7 2
## 5     7   3 6 4
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim)), }\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(USd.agg)), }\DataTypeTok{xlab =} \StringTok{"Constraints"}\NormalTok{, }
    \DataTypeTok{ylab =} \StringTok{"Model output"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{a =} \DecValTok{0}\NormalTok{, }\DataTypeTok{b =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}[htbp]
\centering
\includegraphics{figure/unnamed-chunk-5.png}
\caption{plot of chunk unnamed-chunk-5}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim)), }\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(USd.agg)))}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
## [1] -0.1568
\end{verbatim}
Note that for USd.agg, the results are the same for every zone, as each
individual has a weight of 1 for every zone. The next stage is to apply
the first constraint, to adjust the weights of each individual so they
match the age constraints.

\subsubsection{Constraint 1: age}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{for (j in }\DecValTok{1}\NormalTok{:}\KeywordTok{nrow}\NormalTok{(all.msim)) \{}
    \NormalTok{weights1[}\KeywordTok{which}\NormalTok{(USd$age < }\DecValTok{50}\NormalTok{), j] <- all.msim[j, }\DecValTok{1}\NormalTok{]/USd.agg[j, }\DecValTok{1}\NormalTok{]}
    \NormalTok{weights1[}\KeywordTok{which}\NormalTok{(USd$age >= }\DecValTok{50}\NormalTok{), j] <- all.msim[j, }\DecValTok{2}\NormalTok{]/USd.agg[j, }\DecValTok{2}\NormalTok{]}
\NormalTok{\}}
\CommentTok{# Aggregate the results for each zone}
\NormalTok{for (i in }\DecValTok{1}\NormalTok{:}\KeywordTok{nrow}\NormalTok{(all.msim)) \{}
    \NormalTok{USd.agg1[i, ] <- }\KeywordTok{colSums}\NormalTok{(USd.cat * weights0[, i] * weights1[, i])}
\NormalTok{\}}
\CommentTok{# Test results}
\NormalTok{USd.agg1}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##      16-49 50+     m     f
## [1,]     8   4 6.667 5.333
## [2,]     2   8 6.333 3.667
## [3,]     7   4 6.167 4.833
## [4,]     5   4 5.167 3.833
## [5,]     7   3 5.500 4.500
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.msim}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##   16-49 50+ m f
## 1     8   4 6 6
## 2     2   8 4 6
## 3     7   4 3 8
## 4     5   4 7 2
## 5     7   3 6 4
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim)), }\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(USd.agg1)), }\DataTypeTok{xlab =} \StringTok{"Constraints"}\NormalTok{, }
    \DataTypeTok{ylab =} \StringTok{"Model output"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{a =} \DecValTok{0}\NormalTok{, }\DataTypeTok{b =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}[htbp]
\centering
\includegraphics{figure/unnamed-chunk-6.png}
\caption{plot of chunk unnamed-chunk-6}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim)), }\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(USd.agg1)))}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
## [1] 0.6967
\end{verbatim}
As indicated by the plots and the correlation values, the fit between
the individual-level data and the aggregate constraints (the inpute
data) has been vastly improved, just by constraining by a single
variable. We will perform the test after each constraint to ensure our
model is improving. To see how the weights change for each individual
for each area, type weights1 for constraint 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{weights1}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##       [,1]  [,2]  [,3]  [,4] [,5]
## [1,] 1.333 2.667 1.333 1.333  1.0
## [2,] 1.333 2.667 1.333 1.333  1.0
## [3,] 4.000 1.000 3.500 2.500  3.5
## [4,] 1.333 2.667 1.333 1.333  1.0
## [5,] 4.000 1.000 3.500 2.500  3.5
\end{verbatim}
\subsubsection{Constraint 2: sex}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{for (j in }\DecValTok{1}\NormalTok{:}\KeywordTok{nrow}\NormalTok{(all.msim)) \{}
    \NormalTok{weights2[}\KeywordTok{which}\NormalTok{(USd$sex == }\StringTok{"m"}\NormalTok{), j] <- all.msim[j, }\DecValTok{3}\NormalTok{]/USd.agg1[j, }\DecValTok{3}\NormalTok{]}
    \NormalTok{weights2[}\KeywordTok{which}\NormalTok{(USd$sex == }\StringTok{"f"}\NormalTok{), j] <- all.msim[j, }\DecValTok{4}\NormalTok{]/USd.agg1[j, }\DecValTok{4}\NormalTok{]}
\NormalTok{\}}

\NormalTok{weights3 <- weights0 * weights1 * weights2}
\NormalTok{for (i in }\DecValTok{1}\NormalTok{:}\KeywordTok{nrow}\NormalTok{(all.msim)) \{}
    \NormalTok{USd.agg2[i, ] <- }\KeywordTok{colSums}\NormalTok{(USd.cat * weights3[, i])}
\NormalTok{\}}
\CommentTok{# Test results}
\NormalTok{USd.agg2}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##       [,1]  [,2] [,3] [,4]
## [1,] 8.100 3.900    6    6
## [2,] 2.268 7.732    4    6
## [3,] 7.496 3.504    3    8
## [4,] 4.691 4.309    7    2
## [5,] 6.929 3.071    6    4
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.msim}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##   16-49 50+ m f
## 1     8   4 6 6
## 2     2   8 4 6
## 3     7   4 3 8
## 4     5   4 7 2
## 5     7   3 6 4
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim)), }\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(USd.agg2)), }\DataTypeTok{xlab =} \StringTok{"Constraints"}\NormalTok{, }
    \DataTypeTok{ylab =} \StringTok{"Model output"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{a =} \DecValTok{0}\NormalTok{, }\DataTypeTok{b =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}[htbp]
\centering
\includegraphics{figure/unnamed-chunk-8.png}
\caption{plot of chunk unnamed-chunk-8}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim)), }\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(USd.agg2)))}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
## [1] 0.9942
\end{verbatim}
Again the correlation has improved. Now onto the 3rd constraint

\subsection{Iterations}

The correlation has been improved from one constraint to the next. Even
the after the final constraint (mode), which differs greatly from the
survey data for some zones, the correlation has improved. This
illustrates the robustness of the IPF method. Also note that the
population of each simulated zone is correct. The next step is to
perform further iterations, using the results of the first iteration
(weights4) as our starting point.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{weights0 <- weights3}
\NormalTok{USd.agg}\FloatTok{.1} \NormalTok{<- USd.agg  }\CommentTok{# Saving this for future reference}
\NormalTok{weights3[, }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
## [1] 1.2 1.2 3.6 1.5 4.5
\end{verbatim}
After running this command, simply run the model again, beginning from
the loop at the end of the R code section titled ``Convert survey data
into wide form''. After running constraint 3 the second time, the
correlation is higher: 0.89 instead of 0.86 . Because this is a
relatively simple example, the fit between constraint and simulated
aggregate variables will not improve much beyond this point (notice the
similarity between the plot below - of the final result after the 2nd
iteration - and the plot above).

After the second iteration, the results are as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim)), }\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(USd.agg2)), }\DataTypeTok{xlab =} \StringTok{"Constraints"}\NormalTok{, }
    \DataTypeTok{ylab =} \StringTok{"Model output"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{a =} \DecValTok{0}\NormalTok{, }\DataTypeTok{b =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}[htbp]
\centering
\includegraphics{figure/unnamed-chunk-11.png}
\caption{plot of chunk unnamed-chunk-11}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim)), }\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(USd.agg2)))}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
## [1] 1
\end{verbatim}
\subsection{Interrogating the results}

To view the characteristics of representative individuals for each zone,
the vector associated with the zone in question can be called from the
final weight matrix (weights4 in this case). The individuals that best
match (have the highest weights) for zone five for example, which
contains a high proportion of young cyclists, can be viewed with the
following command:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cbind}\NormalTok{(weights3[, }\DecValTok{5}\NormalTok{], USd)}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##   weights3[, 5] id age sex
## 1         1.068  1  59   m
## 2         1.068  2  54   m
## 3         3.864  3  35   m
## 4         0.866  4  73   f
## 5         3.134  5  49   f
\end{verbatim}
The output from this command illustrates why the final solution of the
IPF procedure is not perfect (i.e.~why the correlation between the
constraint and simulated aggregates cannot be 1): there is only 1
cyclist in the sample population, so she must be replicated 7 times to
fulfill the number of cyclists in the constraint variables, distorting
the other results. This example demonstrates the importance of having a
large and diverse survey dataset from which individuals can be sampled.

For some areas the results are better than others. A breakdown of model
fit by area can be seen by recursively running the correlation command:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{for (i in }\DecValTok{1}\NormalTok{:}\KeywordTok{nrow}\NormalTok{(all.msim)) \{}
    \NormalTok{all.msim$cor[i] <- }\KeywordTok{cor}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim[i, }\DecValTok{1}\NormalTok{:}\DecValTok{4}\NormalTok{])), USd.agg2[i, }
        \NormalTok{])}
\NormalTok{\}}
\NormalTok{all.msim}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##   16-49 50+ m f cor
## 1     8   4 6 6   1
## 2     2   8 4 6   1
## 3     7   4 3 8   1
## 4     5   4 7 2   1
## 5     7   3 6 4   1
\end{verbatim}
Note that zones 1 and 4 are simulated well. This can be explained
because their attributes already fitted with those of original dataset
well:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{for (i in }\DecValTok{1}\NormalTok{:}\KeywordTok{nrow}\NormalTok{(all.msim)) \{}
    \NormalTok{all.msim$cor[i] <- }\KeywordTok{cor}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(all.msim[i, }\DecValTok{1}\NormalTok{:}\DecValTok{4}\NormalTok{])), USd.agg}\FloatTok{.1}\NormalTok{[i, }
        \NormalTok{])}
\NormalTok{\}}
\NormalTok{all.msim}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##   16-49 50+ m f     cor
## 1     8   4 6 6 -0.7071
## 2     2   8 4 6  0.4472
## 3     7   4 3 8 -0.9701
## 4     5   4 7 2  0.5547
## 5     7   3 6 4 -0.3162
\end{verbatim}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{USd.agg}\FloatTok{.1}
\end{Highlighting}
\end{Shaded}
\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    2    3    3    2
## [2,]    2    3    3    2
## [3,]    2    3    3    2
## [4,]    2    3    3    2
## [5,]    2    3    3    2
\end{verbatim}
This illustrates the importance of using a sample survey dataset that is
fairly representative of the aggregated constraint table.

\subsection{Taking IPF further}

This document has provided a succinct run-through of the IPF procedure
in R. This simplified example illustrates how the R programming language
is well-suited to the task, with a number of in-built functions to
manipulate and analyse the data. Because R is an object-orientated
programming language with many add-ons and the ability to define new
functions, the capabilities outlined above only scratch the surface of
what is possible. For example, it would be possible to create new
individuals which have the characteristics most needed to improve the
overall model fit. Also, the possibility of grouping individuals into
household units would greatly add to the technique's ability to simulate
reality (many statistics are collected, and many decisions are made, at
the household level). Another `add-on' that would be particularly useful
for IPF would be the ability to `integerise' the results. Methods for
performing integerisation in R are compared in a paper that accompanies
this document.

The advancement of the IPF procedure will depend not only on
application, but understanding of the underlying theory. This topic is
beyond the scope of this practical guide. Some references on the
underlying theory and applications of IPF are provided below:

\subsection{Key references on IPF and spatial microsimultion}

Note: this list is just a starter and is no way comprehensive

\href{http://www.jstor.org/stable/2235722}{Deming, W., 1940}. On a least
squares adjustment of a sampled frequency table when the expected
marginal totals are known. The Annals of Mathematical Statistics.

\href{http://dx.doi.org/10.1111/j.0033-0124.1992.00340.x}{Wong, D.W.S.,
1992}. The Reliability of Using the Iterative Proportional Fitting
Procedure. The Professional Geographer, 44(3), pp.340--348.

\href{http://eprints.whiterose.ac.uk/5029/1/99-3.pdf}{Norman, P., 1999}.
Putting Iterative Proportional Fitting (IPF) on the Researcher's Desk.
School of Geography, University of Leeds.

\href{www.jrf.org.uk/sites/files/jrf/1859352669.pdf}{Ballas, D. et al.,
2005}. Geography matters: simulating the local impacts of national
social policies, Joseph Roundtree Foundation.

\href{http://linkinghub.elsevier.com/retrieve/pii/S0198971512000336}{Hermes,
K. \& Poulsen, M., 2012}. A review of current methods to generate
synthetic spatial microdata using reweighting and future directions.
Computers, Environment and Urban Systems, 36(4), pp.281--290.

\href{http://www.springerlink.com/index/10.1007/s11116-011-9367-4}{Pritchard,
D.R. \& Miller, E.J., 2012}. Advances in population synthesis: fitting
many attributes per agent and fitting to household and person margins
simultaneously. Transportation, 39(3), pp.685--704.
